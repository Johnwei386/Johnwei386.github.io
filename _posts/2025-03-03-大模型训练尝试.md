---
layout:     post
title:     大模型训练尝试
subtitle:   使用accelerate训练Qwen2-0.5B模型
date:       2025-03-03
author:     Johnwei386
header-img: img/post-bg-rwd.jpg
catalog: true
tags:
    - accelerate
    - llm
---

2022年11月30日，chatGPT正式上线，大语言模型逐渐成为了AI界的主流模型，chatGPT是闭源的模型，采用了强化学习的方式来进行训练，期间研究过其训练方法，但都是浅尝辄止，未深入进行研究，期间经历了一些事情，自身对人工智能也有点失望，认为这不是一条正确道路，但是自己又找不到那条自认为正确的道路，之前花了很多时间研究神经网络的设计，还有线虫，懈怠过，迷茫过，真的很不喜欢这种感觉。

2025年的开年，随着deepseek的开源，deepseek这个本土的AI大模型逐渐席卷大江南北，让我逐渐意识到再不好好深入研究下大模型，我终将被时代狠狠的抛在后面，世界一直在发展，特朗普王者归来，还记得上次他当选总统时，我还在备战考研，^_^（这发不了表情包，哈哈哈），好了，废话少说，deepseek-r1使用了GPRO方法来训练模型，deepseek-r3使用了MOE模型，本人有两张3060的显卡，2021年配的，那会还没有大模型，以前没有显卡的时候，跑训练根本跑不了，我的毕设还是借我室友的2080显卡跑的，他那张显卡当时的显存还是8g的，当时勉强能跑起来bert模型，3060显卡，显存有12G，买的时候是想的，这下跑个一般的模型绝对是够得，结果是世界在变化，短短两年，显卡已经远远不够用了。

## 1. 准备模型和数据集

hugeface是一个类似github的网站，它保存模型参数和数据集数据，使用hugeface下载tldr数据集和Qwen2-0.5B-Instruct模型，该模型参数量只有5亿，大小约为1G，评估该模型的显存占用：

```bash
~$ accelerate estimate-memory Qwen/Qwen2-0.5B-Instruct
┌────────────────────────────────────────┐
│   Memory Usage for loading `Qwen/Qwen2-0.5B-Instruct`    │
├───────┬─────────────┬──────────┬───────┤
│ dtype │Largest Layer│Total Size│   Training using Adam   │
├───────┼─────────────┼──────────┼───────┤
│float32│  519.31 MB  │ 1.84 GB  │         7.36 GB         │
│float16│  259.66 MB  │942.29 MB │         3.68 GB      │
│  int8 │  129.83 MB  │471.15 MB │           N/A               │
│  int4 │   64.91 MB  │235.57 MB │           N/A                 │
└───────┴─────────────┴──────────┴───────┘

```

实际的显存占用比这个值要高，这个只是提供一个参考值，模型训练所占用的显存

下载模型：

```bash
~$ hf_download.py --model Qwen/Qwen2-0.5B-Instruct --save_dir Datums/Researching/
```

下载数据集：

```bash
~$ hf_download.py --dataset trl-lib/tldr --save_dir Datums/Researching/Datasets/
```

 hf_download.py是一个工具，下载地址为：https://github.com/LetheSec/HuggingFace-Download-Accelerator/blob/main/hf_download.py，需安装huggingface_hub，运行在高版本的python环境中，经测试，python3.6版本的huggingface_hub没有download功能，在python3.10版本有此功能。

## 2. 搭建运行的环境

下载完数据集和模型后，需要搭建运行的环境，这里使用anaconda创建python3.10的运行环境deepseek，transformers环境采用https://github.com/huggingface/open-r1.git进行搭建：

```bash
~$ conda create -n deepseek python=3.10
~$ git clone https://github.com/huggingface/open-r1.git
~$ cd open-r1
~$ pip install -e .
```

安装完成后即安装好了基本的运行环境。

## 3. 准备训练的入口程序

根据huggingface官方提供的GRPOTrainer训练器的使用参考案例：

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-

''' 使用GRPOTrainer进行训练 '''

from datasets import load_dataset
from trl import GRPOConfig, GRPOTrainer

# dataset = load_dataset("trl-lib/tldr", split="train")
dataset = load_dataset('/home/john/Datums/Researching/Datasets/trl-lib_tldr/data', split='train')

# Define the reward function, which rewards completions that are close to 20 characters
def reward_len(completions, **kwargs):
    return [-abs(20 - len(completion)) for completion in completions]

training_args = GRPOConfig(output_dir="Qwen2-0.5B-GRPO",
                           per_device_train_batch_size=4,    # 每个GPU上的批次大小
                           gradient_accumulation_steps=2,  # 此参数应与accelerate的配置文件中对应的参数相同,此处默认为1
                           fp16=True,                                                # 启用混合精度训练
                           logging_steps=10,
                          )
trainer = GRPOTrainer(
    model="/home/john/Datums/Researching/Qwen-Qwen2-0.5B-Instruct",
    reward_funcs=reward_len,
    args=training_args,
    train_dataset=dataset,
)
trainer.train()
```

## 4. 使用accelerate进行训练

随后使用`accelerate`进行训练：

```bash
~$ accelerate launch testGRPOTrainer.py
```

会提示`micro_batch_per_gpu * gradient_acc_step * world_size != train_batch_size`的报错，这是因为GRPOConfig的配置与accelerate默认配置有冲突导致的，accelerate的默认配置文件是default_config.yaml文件，其默认地址是`~/.cache/huggingface/accelerate/default_config.yaml`，该文件默认为：

```yaml
compute_environment: LOCAL_MACHINE
debug: true
deepspeed_config:
  gradient_accumulation_steps: auto
  gradient_clipping: auto
  offload_optimizer_device: none
  offload_param_device: none
  zero3_init_flag: true
  zero3_save_16bit_model: true
  zero_stage: 3
distributed_type: DEEPSPEED
downcast_bf16: 'no'
dynamo_config:
  dynamo_backend: INDUCTOR
  dynamo_mode: default
  dynamo_use_dynamic: true
  dynamo_use_fullgraph: true
machine_rank: 0
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

其中gradient_accumulation_steps的参数是auto，我安装的accelerate的版本应该不支持auto这个参数，总之会报一个int类型转换异常的错误，将其改成纯数字可以解决问题，但是我不想改这个源文件，那就采取自定义yaml配置的方式启动训练：

```bash
~$ accelerate launch --config_file ds_config.yaml testGRPOTrainer.py
```

ds_config.yaml是定义在当前目录下的配置文件，基本内容与default_config.yaml文件一致，只有gradient_accumulation_steps的参数设置为。

训练过程中遇到了显存溢出的问题，因为目前我的设备，即使是两张3060显卡，只能做到数据并行，无法实现模型并行，也就是说，当启动训练时，单张显卡就需要加载全部的模型参数，并缓存模型训练过程中的梯度值和优化器状态等，大概为：`总显存占用 = 模型参数 + 梯度+ 优化器状态 + 激活值 + 临时缓冲区 + 其他开销`，若每个参数使用32位浮点数则每个参数占用4个字节，若使用混合精度训练(如FP16)，则每个参数占用2个字节，显然，混合精度训练更加节省显存开销。

`micro_batch_per_gpu` 、`gradient_acc_step` 、 `world_size` 、 `train_batch_size`四个参数存在依赖关系，`train_batch_size = micro_batch_per_gpu * gradient_acc_step * world_size`，启动训练时会核验这个关系是否成立，`world_size`这个参数取的是accelerate的num_processes参数。

**计算train_batch_size:**

当进行训练时，会计算train_batch_size的大小，这个计算的调用逻辑为：



## 5. DeepSpeed

目前训练超大规模语言模型主要有两条技术路线：TPU + XLA + TensorFlow/JAX 和 GPU + PyTorch + Megatron-LM + DeepSpeed，前者与谷歌深度绑定，普通人尝试的可能性低，后者有开源社区与大厂支持，是大家使用都比较多的训练大模型的方法。

使用DeepSpeed加速训练，DeepSpeed是一个由微软开发的开源深度学习优化库，其在在深度学习模型软件体系架构中所处的位置是：

![](https://pic2.zhimg.com/v2-a74db01f155a6b33a95033b6c855af6d_1440w.jpg)

deepspeed主要包含三部分：

- Apis。提供易用的api接口，训练模型、推理模型只需要简单调用几个接口即可。其中最重要的是initialize接口，用来初始化引擎，参数中配置训练参数及优化技术等。配置参数一般保存在config.json文件中。

- runtime。运行时组件，是deepspeed管理、执行和性能优化的核心组件。如部署训练任务到分布式设备、数据分区、模型分区、系统优化、微调、故障检测、checkpoints保存和加载等。该组件使用python语言实现。

- ops。用c++和cuda实现底层内核，优化计算和通信，例如ultrafast transformer kernels, fuse LAN kernels, customary deals等。

  ![](https://pic4.zhimg.com/v2-14d63df4cc578c2e31b6685fac27eb6d_1440w.jpg)



**ZeRO: 一种去除冗余的数据并行方案**

DeepSpeed的核心是ZeRO(Zero Redundancy Optimizer)，简单来说，它是一种显存优化的数据并行(data parallelism, DP)方案，详情见文章：[ZeRO将显存优化到底](https://zhuanlan.zhihu.com/p/513571706)。

